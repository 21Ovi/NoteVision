{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/21Ovi/NoteVision/blob/main/NoteVision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5RiiOfK-h6n"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Welcome to **NoteVision**, a project aimed at converting handwritten notes into digital text using machine learning techniques. This notebook will guide you through the entire process of building a handwriting recognition model using TensorFlow and Python. The dataset used in this project is sourced from Kaggle, consisting of over 400,000 handwritten names.\n",
        "\n",
        "### Notebook Overview:\n",
        "1. **Data Preprocessing**: We begin by loading and preparing the dataset, including image normalization and label encoding.\n",
        "2. **Model Building**: A deep learning model is constructed using TensorFlow, optimized for recognizing handwritten text.\n",
        "3. **Training & Validation**: The model is trained on the dataset and validated for accuracy using Google Colab's GPU resources.\n",
        "4. **Evaluation**: Performance metrics and insights are gathered to assess the effectiveness of the model.\n",
        "5. **Final Model**: The final trained model is saved and ready for deployment.\n",
        "\n",
        "This notebook provides a step-by-step process for building a handwriting recognition system, complete with explanations and code snippets. Feel free to explore and modify it according to your needs!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## All Imports"
      ],
      "metadata": {
        "id": "G5RB7HGBmfSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Lambda, Activation, BatchNormalization, Dropout\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "uDTIJMMeme_5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHAHi6VwLjmP"
      },
      "source": [
        "## Loading Dataset from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oeVPDFi-Z9f",
        "outputId": "bbb574a4-8a9e-4908-e072-59184a479805"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace /content/data/test_v2/test/TEST_0001.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "A\n"
          ]
        }
      ],
      "source": [
        "# Unzip the dataset to a folder in Colab\n",
        "!unzip -q /content/drive/MyDrive/datasets/archive.zip -d /content/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0n9ggQANseV"
      },
      "outputs": [],
      "source": [
        "!ls /content/data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and view data"
      ],
      "metadata": {
        "id": "ZopHE7iZoLJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV files using the correct paths\n",
        "train = pd.read_csv('/content/data/written_name_train_v2.csv')\n",
        "valid = pd.read_csv('/content/data/written_name_validation_v2.csv')\n",
        "test = pd.read_csv('/content/data/written_name_test_v2.csv')\n",
        "\n",
        "# Display the first few rows of each dataset to verify\n",
        "print(\"Train Data:\")\n",
        "print(train.head())\n",
        "print(\"\\nValidation Data:\")\n",
        "print(valid.head())\n",
        "print(\"\\nTest Data:\")\n",
        "print(test.head())\n"
      ],
      "metadata": {
        "id": "0vQD9-OLoET3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### View data"
      ],
      "metadata": {
        "id": "8ikRLrIqoWHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i in range(8):\n",
        "  ax = plt.subplot(2, 4, i+1)\n",
        "  # Updated image path to include the additional 'train' folder\n",
        "  img_dir = '/content/data/train_v2/train/' + train.loc[i, 'FILENAME']\n",
        "  image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "  # Check if the image was loaded properly\n",
        "  if image is None:\n",
        "    print(f\"Image not found or failed to load: {img_dir}\")\n",
        "    continue\n",
        "\n",
        "  plt.imshow(image, cmap='gray')\n",
        "  plt.title(train.loc[i, 'IDENTITY'], fontsize=12)\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.subplots_adjust(wspace=0.2, hspace=-0.8)\n"
      ],
      "metadata": {
        "id": "8HuPLAzJoPYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = len(train)\n",
        "print(f\"Number of samples in the training set: {train_size}\")\n",
        "\n",
        "valid_size = len(valid)\n",
        "print(f\"Number of samples in the validation set: {valid_size}\")\n",
        "\n",
        "test_size = len(test)\n",
        "print(f\"Number of samples in the testing set: {test_size}\")"
      ],
      "metadata": {
        "id": "5gHGFo-_sVoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cleaning Data"
      ],
      "metadata": {
        "id": "hJ2q9v1hsdC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of NaNs in train set       :\", train['IDENTITY'].isnull().sum())\n",
        "print(\"Number of NaNs in validation set: :\", valid['IDENTITY'].isnull().sum())\n",
        "print(\"Number of NaNs in test set        :\", test['IDENTITY'].isnull().sum())"
      ],
      "metadata": {
        "id": "_Fen7OCSsYPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.dropna(inplace=True)\n",
        "valid.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "0FzionGNsmrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also, there are some images in this dataset with the label of `UNREADABLE`, we need to get rid of them in order to clean data."
      ],
      "metadata": {
        "id": "h4gFJl7Qs467"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unreadable = train[train['IDENTITY'] == 'UNREADABLE']\n",
        "unreadable.reset_index(inplace=True, drop=True)\n",
        "\n",
        "plt.figure(figsize=(15, 10))\n",
        "for i in range(6):\n",
        "  ax = plt.subplot(2, 3, i+1)\n",
        "  img_dir = '/content/data/train_v2/train/' + unreadable.loc[i, 'FILENAME']\n",
        "  image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n",
        "  plt.imshow(image, cmap='gray')\n",
        "  plt.title(unreadable.loc[i, 'IDENTITY'], fontsize=12)\n",
        "  plt.axis('off')\n",
        "\n",
        "  plt.subplots_adjust(wspace=0.2, hspace=-0.8)"
      ],
      "metadata": {
        "id": "OfxT9DFHtR2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train[train['IDENTITY'] != 'UNREADABLE']\n",
        "valid = valid[valid['IDENTITY'] != 'UNREADABLE']"
      ],
      "metadata": {
        "id": "ULjWQf2ZuQb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.reset_index(inplace=True, drop=True)\n",
        "valid.reset_index(inplace=True, drop=True)"
      ],
      "metadata": {
        "id": "oQKf8YF5udkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = len(train)\n",
        "print(f\"Number of samples in the training set: {train_size}\")\n",
        "\n",
        "valid_size = len(valid)\n",
        "print(f\"Number of samples in the validation set: {valid_size}\")\n",
        "\n",
        "test_size = len(test)\n",
        "print(f\"Number of samples in the testing set: {test_size}\")"
      ],
      "metadata": {
        "id": "sNeWZGVFuhS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing and preparing the images for training\n",
        "\n",
        "* The images are loaded as grayscale and reshaped to width 256 and height 64.\n",
        "* The width and height are cropped if they are greater than 256 and 64 respectively. If they are smaller, then the image is padded with white pixels. Finally the image is rotated clockwise to bring the image shape to (x, y).\n",
        "* The image is then normalized to range [0, 1]"
      ],
      "metadata": {
        "id": "zJpLFtMaPWU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(img):\n",
        "    (h, w) = img.shape\n",
        "\n",
        "    final_img = np.ones([64, 256])*255 # blank white image\n",
        "\n",
        "    # crop\n",
        "    if w > 256:\n",
        "        img = img[:, :256]\n",
        "\n",
        "    if h > 64:\n",
        "        img = img[:64, :]\n",
        "\n",
        "\n",
        "    final_img[:h, :w] = img\n",
        "    return cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE)"
      ],
      "metadata": {
        "id": "b5hGQ-gjukqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model will be trained on 30000 images and validate on 3000 images\n",
        "\n"
      ],
      "metadata": {
        "id": "Tm0ZQg_3PjMw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ff2Xg-_zPsva"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "12MLhJybWuyPlmIjPzNqQHTr6RTZ7ZQoD",
      "authorship_tag": "ABX9TyOVw7ivvpoNNhLI4KO79fVp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}